{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summit import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform inputs\n",
    "def get_ct(continuous_features, ordinal_features):\n",
    "    transformers = []\n",
    "    transformers.append(\n",
    "        (\n",
    "            \"continuous\",\n",
    "            StandardScaler(),\n",
    "            continuous_features\n",
    "        )\n",
    "    )\n",
    "    if type(ordinal_features) == list:\n",
    "        transformers.append(\n",
    "            (\n",
    "                \"ordinal\",\n",
    "                OrdinalEncoder(),\n",
    "                ordinal_features\n",
    "            )\n",
    "        )\n",
    "    elif type(ordinal_features) == dict:\n",
    "        categories = [cats for cats in ordinal_features.values()]\n",
    "        transformers.append(\n",
    "            (\n",
    "                \"ordinal\",\n",
    "                OrdinalEncoder(categories=categories),\n",
    "                list(ordinal_features.keys())\n",
    "            )\n",
    "        )\n",
    "    return ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-276246e1e82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mparity_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Train resultss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_y_pred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def parity_plot(result: dict, ax: plt.Axes = None):\n",
    "    # Train resultss\n",
    "    model = result[\"model\"]\n",
    "    train_posterior = model.posterior(torch.tensor(result[\"train_X\"]))\n",
    "    train_y_pred_mean = train_posterior.mean.detach()\n",
    "    train_y_pred_std = train_posterior.variance.sqrt()\n",
    "    train_y_pred_mean = result[\"output_transform\"].inverse_transform(train_y_pred_mean)\n",
    "    train_y = result[\"output_transform\"].inverse_transform(result[\"train_y\"])\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1)\n",
    "    ax.plot([0,100], [0,100], \"--\")\n",
    "    ax.scatter(train_y, train_y_pred_mean, label=\"Train\")\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_ylim(0,100)\n",
    "    \n",
    "    if result.get(\"test_X\") is not None and result.get(\"test_y\") is not None:\n",
    "        test_posterior = model.posterior(torch.tensor(result[\"test_X\"]))\n",
    "        test_y_pred_mean = test_posterior.mean.detach()\n",
    "        test_y_pred_std = test_posterior.variance.sqrt()\n",
    "        test_y_pred_mean = result[\"output_transform\"].inverse_transform(test_y_pred_mean)\n",
    "        test_y = result[\"output_transform\"].inverse_transform(result[\"test_y\"])\n",
    "        \n",
    "        ax.scatter(test_y, test_y_pred_mean, label=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id='domain' width=100%><tr><td><b>Name</b></td><td><b>Type</b></td><td><b>Description</b></td><td><b>Values</b></td></tr><tr><td>conc_cat</td><td>continuous, input</td><td>catalyst concentration</td><td>[0.000835,0.004175]</td></tr><tr><td>t</td><td>continuous, input</td><td>reaction time</td><td>[60,600]</td></tr><tr><td>cat_index</td><td>categorical, input</td><td>Choice of catalyst</td><td>8 levels</td></tr><tr><td>temperature</td><td>continuous, input</td><td>Reactor temperature in degress celsius</td><td>[30,110]</td></tr><tr><td>y</td><td>continuous, maximize objective</td><td>yield (%)</td><td>[0,100]</td></tr></table>"
      ],
      "text/plain": [
       "<summit.domain.Domain at 0x7fe83865ee10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_pt = MIT_case1(noise_level=1)\n",
    "exp_pt.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate different amounts of data using latin hypercube sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run single-task and multi-task Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mit_case_1_data(n_points):\n",
    "    exp_pt = MIT_case1(noise_level=1)\n",
    "    rs = np.random.RandomState(100)\n",
    "    lhs = LHS(exp_pt.domain, random_state=rs)\n",
    "    conditions = lhs.suggest_experiments(n_points)\n",
    "    exp_pt.run_experiments(conditions)\n",
    "    pt_data = exp_pt.data\n",
    "    pt_data['task', 'METADATA'] = 0\n",
    "    return pt_data\n",
    "\n",
    "n_aux = [5, 10, 50]\n",
    "aux_datasets = [generate_mit_case_1_data(n) for n in n_aux]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mit_case_2_data(n_points):\n",
    "    exp_pt = MIT_case2(noise_level=1)\n",
    "    rs = np.random.RandomState(100)\n",
    "    lhs = LHS(exp_pt.domain, random_state=rs)\n",
    "    conditions = lhs.suggest_experiments(n_points)\n",
    "    exp_pt.run_experiments(conditions)\n",
    "    pt_data = exp_pt.data\n",
    "    pt_data['task', 'METADATA'] = 1\n",
    "    return pt_data\n",
    "\n",
    "data = generate_mit_case_2_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Single Task Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_task_model(df, include_continuous=True):\n",
    "    continuous_features = [\n",
    "        \"conc_cat\", \"temperature\", \"t\"\n",
    "    ]\n",
    "    categorical_features = [\"cat_index\"]\n",
    "    features = categorical_features\n",
    "    if include_continuous:\n",
    "        features += continuous_features\n",
    "    features.append(\"y\")\n",
    "    df = df.copy()[features]\n",
    "\n",
    "    if include_continuous:\n",
    "        input_transform = get_ct(\n",
    "            continuous_features=continuous_features,\n",
    "            ordinal_features=categorical_features)\n",
    "    else:   \n",
    "        input_transform = OrdinalEncoder()\n",
    "        \n",
    "    train_X = input_transform.fit_transform(df)\n",
    "    output_scaler = StandardScaler()\n",
    "    train_y = output_scaler.fit_transform(df[[\"y\"]])\n",
    "\n",
    "    model = MixedSingleTaskGP(\n",
    "        train_X=torch.tensor(train_X),\n",
    "        train_Y=torch.tensor(train_y),\n",
    "        cat_dims=\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    return {\n",
    "        \"input_transform\": input_transform,\n",
    "        \"output_transform\": output_scaler,\n",
    "        \"train_X\": train_X,\n",
    "        \"train_y\": train_y,\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Selected columns, ['conc_cat', 'temperature', 't'], are not unique in dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-411d53e427d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_single_task_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c467cb574b27>\u001b[0m in \u001b[0;36mtrain_single_task_model\u001b[0;34m(df, include_continuous)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minput_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moutput_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/multitask-z7ErTcQa-py3.7/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/multitask-z7ErTcQa-py3.7/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/multitask-z7ErTcQa-py3.7/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                     raise ValueError(f\"Selected columns, {columns}, are not \"\n\u001b[0m\u001b[1;32m    399\u001b[0m                                      \"unique in dataframe\")\n\u001b[1;32m    400\u001b[0m                 \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Selected columns, ['conc_cat', 'temperature', 't'], are not unique in dataframe"
     ]
    }
   ],
   "source": [
    "train_single_task_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ICM and LCM models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multitask",
   "language": "python",
   "name": "multitask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
